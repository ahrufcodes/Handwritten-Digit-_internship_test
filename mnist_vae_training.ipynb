{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# MNIST Handwritten Digit Generation with VAE\n",
        "\n",
        "This notebook trains a Variational Autoencoder (VAE) from scratch to generate handwritten digits using the MNIST dataset.\n",
        "\n",
        "**Training Environment:** Google Colab with T4 GPU  \n",
        "**Framework:** PyTorch  \n",
        "**Dataset:** MNIST (28x28 grayscale images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (if needed)\n",
        "%pip install torch torchvision matplotlib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"PyTorch Version: {torch.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 50\n",
        "LATENT_DIM = 20\n",
        "INPUT_DIM = 784  # 28x28\n",
        "\n",
        "print(f\"Training Configuration:\")\n",
        "print(f\"- Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"- Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"- Epochs: {EPOCHS}\")\n",
        "print(f\"- Latent Dimension: {LATENT_DIM}\")\n",
        "print(f\"- Input Dimension: {INPUT_DIM}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VAE Model Architecture\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        # Encoder\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc21 = nn.Linear(hidden_dim, latent_dim)  # mu layer\n",
        "        self.fc22 = nn.Linear(hidden_dim, latent_dim)  # logvar layer\n",
        "        \n",
        "        # Decoder\n",
        "        self.fc3 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "    \n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "    \n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 784))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "# Loss function\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "    \n",
        "    # KLD = -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    \n",
        "    return BCE + KLD\n",
        "\n",
        "print(\"VAE Model and Loss Function Defined!\")\n",
        "print(\"Architecture:\")\n",
        "print(\"- Encoder: FC(784→400) → FC(400→20×2)\")\n",
        "print(\"- Decoder: FC(20→400) → FC(400→784)\")\n",
        "print(\"- Loss: BCE + KLD\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
